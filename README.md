# Explainable-AI-Computer-Vision
Explainable artificial intelligence (XAI) is a set of processes and methods that allows human users to comprehend and trust the results and output created by machine learning algorithms. Explainable AI is used to describe an AI model, its expected impact and potential biases. It helps characterize model accuracy, fairness, transparency and outcomes in AI-powered decision making. Explainable AI is crucial for an organization in building trust and confidence when putting AI models into production. AI explainability also helps an organization adopt a responsible approach to AI development.

As AI becomes more advanced, humans are challenged to comprehend and retrace how the algorithm came to a result. The whole calculation process is turned into what is commonly referred to as a â€œblack box" that is impossible to interpret. These black box models are created directly from the data. And, not even the engineers or data scientists who create the algorithm can understand or explain what exactly is happening inside them or how the AI algorithm arrived at a specific result.

There are many advantages to understanding how an AI-enabled system has led to a specific output.  Explainability can help developers ensure that the system is working as expected, it might be necessary to meet regulatory standards, or it might be important in allowing those affected by a decision to challenge or change that outcome.

# Grad-CAM Example
![image](https://user-images.githubusercontent.com/77681678/228993531-c5438e88-e192-44a6-abe2-119daf36300c.png)
![image](https://user-images.githubusercontent.com/77681678/228993545-70e3d976-00ab-4c02-b77a-bb18d041a75a.png)
![image](https://user-images.githubusercontent.com/77681678/228993563-be93cadb-1fab-4e4d-81e8-d0b26470481c.png)

